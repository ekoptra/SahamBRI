{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "Melakukan analisis sentimen pada data menggunakan model VADER. Data yang digunakan adalah data berita yang sudah di translate yang disimpan dalam folder `data/translate.txt`. Hasil sentimen skornya kemudian disimpan `data/data_vader.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import json\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_random(df, category_sentiment, column):\n",
    "    data = df[df.category_sentiment == category_sentiment].sample(1)\n",
    "    print(\"Sentiment Score :\", data[column].to_list()[0])\n",
    "    print(\"Link Article :\", data.link.to_list()[0])\n",
    "    print(data.content.to_list()[0])\n",
    "    \n",
    "def category_sentiment(compound, threshold_neg=-0.05, threshold_pos=0.05):\n",
    "    if compound is None : return  None\n",
    "    if compound < threshold_neg : return \"Negative\"\n",
    "    if compound > threshold_pos : return \"Positive\"\n",
    "    return \"Netral\"\n",
    "\n",
    "def clean_text(text):\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "    text = re.sub(\"\\xad\", \"\", text)\n",
    "    \n",
    "    # hapus titik dibeberapa kata tertentu\n",
    "    text = re.sub(\" Tbk\\.\", \" Tbk \", text)\n",
    "    text = re.sub(\" Tbk\", \" Tbk \", text)\n",
    "    text = re.sub(\" Rp\\.\", \" \", text)\n",
    "    text = re.sub(\" Rp\", \" \", text)\n",
    "    text = re.sub(\" PT\\.\", \" PT \", text)\n",
    "    text = re.sub(\" Pt\\.\", \" PT \", text)\n",
    "    text = re.sub(\" dr\\.\", \" \", text)\n",
    "    text = re.sub(\" Dr\\.\", \" \", text)\n",
    "    text = re.sub(\" DR\\.\", \" \", text)\n",
    "    text = re.sub(\" N\\.A\\.\", \" \", text)\n",
    "    text = re.sub(\" H\\.M\\.\", \" HM\", text)    \n",
    "    text = re.sub(\" jl\\. \", \" jalan \", text)\n",
    "    text = re.sub(\" Jl\\. \", \" jalan \", text)\n",
    "    text = re.sub(\" Jln\\. \", \" jalan \", text)\n",
    "    text = re.sub(\" jln\\. \", \" jalan \", text)    \n",
    "\n",
    "    # stop words\n",
    "    text = re.sub(\"Berikut rincian kurs jual-beli.*$\", \"\", text)\n",
    "    text = re.sub(\"(Simak berita lainnya seputar topik.+)$\", \"\", text)\n",
    "    text = re.sub(\"--.*--\", \" \", text) # hapus semua kalimat yang ada di tengah -- dan --\n",
    "    \n",
    "    # others pattern\n",
    "    text = re.sub(r\"\\. *[0-9]+\\. \", \". \", text) # hapus angka yang menunjukkan list seperti 1. 2. yang diawali dengan titik\n",
    "    text = re.sub(r\": *[0-9]+\\. \", \". \", text) # hapus angka yang menunjukkan list seperti 1. 2. yang diawali dengan \":\"\n",
    "    text = re.sub(\"(?<=\\d)(?=[a-zA-Z])\", \" \", text) # memisahkan angka yang berdempetan dengan huruf\n",
    "    text = re.sub(\"(?<=[a-zA-Z])(?=\\d)\", \" \", text) # memisahkan huruf yang berdempetan dengan angka\n",
    "    text = re.sub(\" ([a-zA-Z]{1,2})\\. \", \" \", text) # hapus dua huruf yang diikuti titik karena biasa hanya singkatan nama\n",
    "    \n",
    "    # hapus url\n",
    "    text = re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \"link-website\", text)\n",
    "    \n",
    "    text = re.sub(\"\\*\", \"\", text) # hapus bintang\n",
    "    text = re.sub(r\"(?<=\\d)[,.](?=\\d)\", \"\", text) # hapus titik atau koma ditengah angka\n",
    "    text = re.sub(\":\", \": \", text) # menambahkan spasi setelah :\n",
    "    text = re.sub(r\"\\.(?=\\S)\", \". \", text) # ada spasi setelah titik\n",
    "    text = re.sub(r\"\\?(?=\\S)\", \"? \", text) # ada spasi setelah tanda tanya\n",
    "    text = re.sub(r\"\\)(?=\\S)\", \") \", text) # ada spasi setelah tutup kurung\n",
    "    text = re.sub(r\"\\((?=\\S)\", \" (\", text) # ada spasi sebelum tutup kurung\n",
    "\n",
    "    text = re.sub(\"\\. +\\.\", \".\", text) # hapus spasi diantara dua titik\n",
    "    text = re.sub(\" +\\? +\", \"? \", text) # hapus spasi sebelum tanda tanya\n",
    "    text = re.sub(\" +,\", \", \", text) # hapus spasi sebelum koma\n",
    "    text = re.sub(\" +\\. \", \". \", text) # hapus spasi sebelum titik\n",
    "    text = re.sub(\"\\.,\", \", \", text) # hapus .,\n",
    "    \n",
    "    text = re.sub(\" {2,}\", \" \", text) # hapus spasi yang berulang\n",
    "    text = re.sub(\"\\.{2,}\", \".\", text) # hapus titik yang berulang\n",
    "    text = re.sub(\"\\?{2,}\", \".\", text) # hapus tanda tanya yang berulang\n",
    "    \n",
    "    text = re.sub(r'\\. *\\([^)]*\\)[\\. ]', \". \", text) # hapus kurung di awal kalimat\n",
    "    text = re.sub(r'\\. *\\([^)]*\\)$', \".\", text) # hapus kurung di akhir artikel\n",
    "    \n",
    "    text = re.sub(\" Bisnis\\.com\", \" bisniscom\", text)\n",
    "    text = re.sub(\" Bisnis\\. com\", \" bisniscom\", text)\n",
    "    text = re.sub(\" bisnis\\. com\", \" bisniscom\", text)\n",
    "    text = re.sub(\" bisnis\\.com\", \" bisniscom\", text)\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def veder_sentiment(row, column):\n",
    "    \"\"\"Callback for dataframe to do sentiment analysis\n",
    "    with VADER. Dataframe must contain translate_text column\n",
    "    \"\"\"\n",
    "    # print(row['id'])\n",
    "    text = row[column]\n",
    "    if text is not None:     \n",
    "        per_sentence = []\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        compound = neg = pos = neu = 0\n",
    "        sentence_length = len(sentences)\n",
    "        for i, sentence in zip(range(1, sentence_length + 1), sentences):\n",
    "            sentiment = sid.polarity_scores(sentence.replace('\"', \"\"))    \n",
    "            compound += sentiment['compound']\n",
    "            neg += sentiment['neg']\n",
    "            pos += sentiment['pos']\n",
    "            neu += sentiment['neu']\n",
    "            per_sentence.append({\n",
    "                \"sentence_ke\" : i,\n",
    "                \"sentence\" : sentence,\n",
    "                \"sentiment\" : sentiment\n",
    "            })\n",
    "        \n",
    "        row['mean_compound'] = compound / sentence_length\n",
    "        row['mean_pos'] = pos / sentence_length\n",
    "        row['mean_neg'] = neg / sentence_length\n",
    "        row['mean_neu'] = neu / sentence_length\n",
    "        row['per_sentence'] = per_sentence\n",
    "        \n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/translate.txt\", \"r\", encoding='utf-8') as f:\n",
    "    data_translate = json.load(f)\n",
    "\n",
    "data_translate = pd.DataFrame(data_translate)\n",
    "data = pd.read_json(\"data/table_articles.json\")\n",
    "\n",
    "data = (data.set_index(\"link\")\n",
    "        .join(data_translate.set_index(\"link\"))\n",
    "        .reset_index())\n",
    "\n",
    "data['content_clean'] = data.content.apply(clean_text)\n",
    "\n",
    "data_veder = data.apply(lambda row : veder_sentiment(row, 'translate_text'), axis=1)\n",
    "data_veder.to_json('data/data_vader.json')\n",
    "\n",
    "data_veder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('skripsi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6f7feddf18c8ecc9fa0d09c723cea7fa4b6247af6f300fc40fbf3468d2ad1be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
